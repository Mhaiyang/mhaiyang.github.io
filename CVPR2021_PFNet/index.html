<!DOCTYPE html>
<html>
<head>
<title>CVPR2021_PFNet</title>

<style media="screen" type="text/css">
body
{
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1080px;
  font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #fdfdfd;
}
</style>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>


</head>

<body>
<h3 align="center"><i><font size="3" face="Palatino Linotype">IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR) 2021</font></i></h3>

<table align="center">
<td align="center">
<h1>Camouflaged Object Segmentation with Distraction Mining</h1>
<h3>
	<a href="http://mhaiyang.github.io" target="_blank"><font size="3"><b>Haiyang Mei</b></font></a><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Ge-Peng Ji</b></font><sup><font size="2">2</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Ziqi Wei</b></font><sup><font size="2">3</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="http://faculty.dlut.edu.cn/yangxin/zh_CN/index/949121/list/index.htm" target="_blank"><font size="3"><b>Xin Yang</b></font></a><sup><font size="2">1,*</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Xiaopeng Wei</b></font><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="http://dpfan.net" target="_blank"><font size="3"><b>Deng-Ping Fan</b></font></a><sup><font size="2">4</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<!--<font size="3">Xiaopeng Wei</font><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;-->
</h3>


<sup><font size="2">1</font></sup>
<b><a><font size="3">Dalian University of Technology</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">2</font></sup>
<b><a><font size="3">Wuhan University</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">3</font></sup>
<b><a><font size="3">Tsinghua University</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">4</font></sup>
<b><a><font size="3">IIAI</font></a></b>

<!--<br>-->
<!--<br>&nbsp;-->
<!--&lt;!&ndash;<sup><font size="2">&dagger;</font></sup>&ndash;&gt;-->
<!--<sup><font size="3">*</font></sup>-->
<!--<a><font size="3"> Corresponding author</font></a>-->
<br>
<br>&nbsp;

	<b><a><font size="3"> Contact us:&nbsp;&nbsp;&nbsp;&nbsp;<i>xinyang@dlut.edu.cn&nbsp;&nbsp;&nbsp;&nbsp;mhy666@mail.dlut.edu.cn</i></font></a></b>

</td>
</table>


<br><br>
<table align="center">
<tr>
	<td align="center"><img border=0 height=450 width=900 src="camouflaged.gif"></td>
</tr>
</table>

<!--<br>-->
<!--<table align="center">-->
<!--<tr>-->
	<!--<td align="center"><img border=0 height=350 width=800 src="Glass.gif"></td>-->
<!--</tr>-->
<!--</table>-->

<br>
<h2><p><font size="6"><b>Abstract</b></font></p></h2>
<hr/>
<p><font size="4" face="Palatino Linotype">Camouflaged object segmentation (COS) aims to identify objects that are ''perfectly'' assimilate into their surroundings, which has a wide range of valuable applications. The key challenge of COS is that there exist high intrinsic similarities between the candidate objects and noise background. In this paper, we strive to embrace challenges towards effective and efficient COS. To this end, we develop a bio-inspired framework, termed Positioning and Focus Network (PFNet), which mimics the process of predation in nature. Specifically, our PFNet contains two key modules, i.e., the positioning module (PM) and the focus module (FM). The PM is designed to mimic the detection process in predation for positioning the potential target objects from a global perspective and the FM is then used to perform the identification process in predation for progressively refining the coarse prediction via focusing on the ambiguous regions. Notably, in the FM, we develop a novel distraction mining strategy for the distraction region discovery and removal, to benefit the performance of estimation. Extensive experiments demonstrate that our PFNet runs in real-time (72 FPS) and significantly outperforms 18 cutting-edge models on three challenging benchmark datasets under four standard metrics. The code will be made publicly available.
</font></p>


<br>
<h2><p><font size="6"><b>PFNet</b></font></p></h2>
<hr/>
<table align="center">
<tr>
	<!--<td align="center"><img border=0 height=270 width=960 src="pipeline.png"></td>-->
</tr>
</table>

<br>
<h2><p><font size="6"><b>Visual Results</b></font></p></h2>
<hr/>
<table align="center">
<tr>
	<!--<td align="center"><img border=0 height=300 width=900 src="CVPR2020_Glass_1.gif"></td>-->
</tr>
</table>


<br>
<h2><p><font size="6"><b>Downloads</b></font></p></h2>
<hr/>
<div align="left">
		<table>						
		<tr align="left">
		<td>
			<font size="4">Paper</font>
		</td>
		<td>
			<font size="4">: [ PFNet.pdf ]</font>
			<!--<font size="4">: <a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Mei_Dont_Hit_Me_Glass_Detection_in_Real-World_Scenes_CVPR_2020_paper.pdf" target="_blank">[ GDNet.pdf ]</a></font>-->
		</td>
		</tr>

		<!--<tr align="left">-->
		<!--<td>-->
			<!--<font size="4">Glass Detection Dataset</font>-->
		<!--</td>-->
		<!--<td>-->
		<!--<font size="4">: [ Google Drive ]</font>-->
		<!--&lt;!&ndash;<font size="4">: <a href="" target="_blank">[ Google Drive ]</a></font>&ndash;&gt;-->
		<!--</td>-->
		<!--</tr>-->
							
		<tr align="left">
		<td>
			<font size="4">Experimental results</font>
		</td>
		<td>
		<font size="4">: [ Results.zip ]</font>
		<!--<font size="4">: <a href="https://drive.google.com/file/d/19Oa5Nnw_UKFE7SHSatHrU-5hHJYE3A9G/view?usp=sharing" target="_blank">[ Results.zip ]</a></font>-->
		</td>

		</tr>

		<tr align="left">
		<td>
			<font size="4">Pre-trained model.</font>
		</td>
		<td>
			<font size="4">: [ PFNet.pth ]</font>
			<!--<font size="4">: <a href="https://drive.google.com/file/d/1xOwuH9lWizGVnPmEH77_81Sp9EAN054O/view?usp=sharing" target="_blank">[ GDNet.pth ]</a></font>-->
		</td>
		</tr>
					
		<tr align="left">
		<td>
			<font size="4">Source Code.</font>
		</td>
		<td>
			<font size="4">: [ Code ]</font>
			<!--<font size="4">: <a href="https://github.com/Mhaiyang/CVPR2020_GDNet" target="_blank">[ Code ]</a> </font>-->
		</td>
		</tr>	
			
			
		</table>
</div>
<br>
<br>


<h2><p><font size="6" color="black"><b>Dataset</b></font></p></h2>
<hr/>

<!--<font size="4"> Both <font size="4" color="red">training set</font> and <font size="4" color="red">testing set</font> can be obtained via e-mail request! </font>-->
<!--<br><br>-->

<!--<font size="3">-->
	<!--To request access to the dataset for non-commercial use, please review the terms and conditions. If you agree with them, please send us a request (<b>Prof. Xin Yang, xinyang@dlut.edu.cn</b>). Also, please use your official university/company email address. Thank you!-->

	<!--<br>-->
	<!--<br>-->

	<!--<b>Terms and Conditions</b>-->
	<!--<br>-->

<!--The dataset can be used freely if you agree with all the following terms.<br>-->

<!-- - The dataset is used only for non-commercial purposes, such as teaching and research. You do not use the dataset or any of its modified versions for any purposes of commercial advantage or private financial gain.<br>-->
<!-- - You do not distribute the dataset or any of its modified versions to other individuals, institutes, companies, associations or public.<br>-->
<!-- - In case you use the dataset within your research papers, you refer to our publications on our website. If the dataset is used in media, a link to our website is included.<br>-->
<!-- - We reserve all rights that are not explicitly granted to you. The dataset is provided as is, and you take full responsibility for any risk of using it. There may be inaccuracies although we tried, and will try our best to rectify any inaccuracy once found.-->

</font>


<h2><p><font size="6" color="black"><b>BibTex</b></font></p></h2>
<hr/>
<font size="3">
@InProceedings{Mei_2021_CVPR,<br>
&nbsp;&nbsp;&nbsp;&nbsp;author = {Mei, Haiyang and Ji, Ge-Peng and Wei, Ziqi and Yang, Xin and Wei, Xiaopeng and Fan, Deng-Ping},<br>
&nbsp;&nbsp;&nbsp;&nbsp;title = {Camouflaged Object Segmentation with Distraction Mining},<br>
&nbsp;&nbsp;&nbsp;&nbsp;booktitle = {IEEE/CVF Conference on Computer Vision and Pattern Recognition (CVPR)},<br>
&nbsp;&nbsp;&nbsp;&nbsp;month = {June},<br>
&nbsp;&nbsp;&nbsp;&nbsp;year = {2021}<br>
}
</font>


<br><br>
<h2>Website visit statistics</h2>
<hr/>
<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=a&t=tt&d=oltD0PapAwP93FMgNPzI2JHNLRqAH6vR4MZNpNrmmHY'></script>

</body>

</html>
