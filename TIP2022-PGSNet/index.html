<!DOCTYPE html>
<html>
<head>
<title>TIP2022_PGSNet</title>

<style media="screen" type="text/css">
body
{
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1080px;
  font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #fdfdfd;
}
</style>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>
	<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
	<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.8.0.js"></script>
</head>

<body>
<h3 align="center"><i><font size="3" face="Palatino Linotype">IEEE Transactions on Image Processing (TIP) 2022</font></i></h3>

<table align="center">
<td align="center">
<h1>Progressive Glass Segmentation</h1>
<h3>
	<font size="3"><b>Letian Yu</b></font><sup><font size="2">1,*</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="http://mhaiyang.github.io" target="_blank"><font size="3"><b>Haiyang Mei</b></font></a><sup><font size="2">1,*</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Wen Dong</b></font><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Ziqi Wei</b></font><sup><font size="2">2,&dagger;</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Li Zhu</b></font><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Yuxin Wang</b></font><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="https://xinyangdut.github.io/" target="_blank"><font size="3"><b>Xin Yang</b></font></a><sup><font size="2">1,&dagger;</font></sup>
	<br>
</h3>

<sup><font size="2">1</font></sup>
<b><a><font size="3">Dalian University of Technology</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">2</font></sup>
<b><a><font size="3">Tsinghua University</font></a></b>

<br>
<br>
<sup><font size="2">*</font></sup>
<a><font size="2">Joint first authors</font></a>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">&dagger;</font></sup>
<a><font size="2"> Corresponding authors</font></a>

<br>
<br>&nbsp;
	<b><a><font size="3"> Contact us:&nbsp;&nbsp;&nbsp;&nbsp;<i>xinyang@dlut.edu.cn&nbsp;&nbsp;&nbsp;&nbsp;mhy666@mail.dlut.edu.cn&nbsp;&nbsp;&nbsp;&nbsp;letianyu@mail.dlut.edu.cn</i></font></a></b>
</td>
</table>


<br><br>
<table align="center">
<tr>
	<td align="center"><img border=0 height=250 width=1000 src="pipeline.png"></td>
</tr>
</table>


<br>
<h2><p><font size="6"><b>Abstract</b></font></p></h2>
<hr/>
<p><font size="4" face="Palatino Linotype">Glass is very common in the real world. Influenced by the uncertainty about the glass region and the varying complex scenes behind the glass, the existence of glass poses severe challenges to many computer vision tasks, making glass segmentation as an important computer vision task. Glass does not have its own visual appearances but only transmit/reflect the appearances of its surroundings, making it fundamentally different from other common objects. To address such a challenging task, existing methods typically explore and combine useful cues from different levels of features in the deep network. As there exists a characteristic gap between level-different features, i.e., deep layer features embed more high-level semantics and are better at locating the target objects while shallow layer features have larger spatial sizes and keep richer and more detailed low-level information, fusing these features naively thus would lead to a sub-optimal solution. In this paper, we approach the effective features fusion towards accurate glass segmentation in two steps. First, we attempt to bridge the characteristic gap between different levels of features by developing a Discriminability Enhancement (DE) module which enables level-specific features to be a more discriminative representation, alleviating the features incompatibility for fusion. Second, we design a Focus-and-Exploration Based Fusion (FEBF) module to richly excavate useful information in the fusion process by highlighting the common and exploring the difference between level-different features. Combining these two steps, we construct a Progressive Glass Segmentation Network (PGSNet) which uses multiple DE and FEBF modules to progressively aggregate features from high-level to low-level, implementing a coarse-to-fine glass segmentation. In addition, we build the first home-scene-oriented glass segmentation dataset for advancing household robot applications and in-depth research on this topic. Extensive experiments demonstrate that our method outperforms 26 cutting-edge models on three challenging datasets under four standard metrics.
</font></p>


<h4><p><font size="6"><b>Downloads</b></font></p></h4>
<div align="left">
		<table>

		<tr align="left">
		<td>
			<font size="4">HSO training set</font>
		</td>
		<td>
			<font size="4">: [ <a href="" target="_blank">Google Drive</a> ]</font>
			<font size="4">[ <a href="" target="_blank">Baidu Disk</a>, fetch code: hsod ]</font>
<!--			<font size="4">: [ Google Drive ]</font>-->
<!--			<font size="4">[ Microsoft OneDrive ]</font>-->
<!--			<font size="4">[ Baidu Disk, fetch code: xxxx ]</font>-->
		</td>
		</tr>
		<tr align="left">
		<td>
			<font size="4">HSO testing set</font>
		</td>
		<td>
			<font size="4">: [ <a href="" target="_blank">Google Drive</a> ]</font>
			<font size="4">[ <a href="" target="_blank">Baidu Disk</a>, fetch code: hsod ]</font>
<!--			<font size="4">: [ Google Drive ]</font>-->
<!--			<font size="4">[ Microsoft OneDrive ]</font>-->
<!--			<font size="4">[ Baidu Disk, fetch code: xxxx ]</font>-->
		</td>
		</tr>

		<tr align="left">
		<td>
			<font size="4">Code</font>
		</td>
		<td>
			<!--<font size="4">: [ Code ]</font>-->
			<font size="4">: [ <a href="https://github.com/Mhaiyang/TIP2022_PGSNet" target="_blank">Github</a> ] (under-construction) </font>
		</td>
		</tr>

		</table>
</div>


<h2><p><font size="6" color="black"><b>BibTex</b></font></p></h2>
<hr/>
<font size="3">
@article{Yu_2022_TIP_PGSNet,<br>
&nbsp;&nbsp;&nbsp;&nbsp;author = {Yu, Letian and Mei, Haiyang and Dong, Wen and Wei, Ziqi and Zhu, Li and Wang, Yuxin and Yang, Xin},<br>
&nbsp;&nbsp;&nbsp;&nbsp;title = {Progressive Glass Segmentation},<br>
&nbsp;&nbsp;&nbsp;&nbsp;journal = {IEEE Transactions on Image Processing (TIP)},<br>
&nbsp;&nbsp;&nbsp;&nbsp;year = {2022}<br>
}
</font>


<br><br>
<h2>Website visit statistics</h2>
<hr/>
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/1.js?i=589ghcprplm&amp;s=258&amp;m=0&amp;v=true&amp;r=false&amp;b=000000&amp;n=false&amp;c=ff0000" async="async"></script>


<script type="text/javascript" src="https://cdn.jsdelivr.net/npm/emailjs-com@2/dist/email.min.js"></script>
<script type="text/javascript">
   (function(){
      emailjs.init("user_objBJSsyEdqmhf8JaUiLu");
   })();
</script>
<script type="text/javascript" src="https://mhaiyang.github.io/CVPR2021_PDNet/main.js"></script>

</body>

</html>
