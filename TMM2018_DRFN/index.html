<!DOCTYPE html>
<html>
<head>
<title>TMM2018_DRFN</title>

<style media="screen" type="text/css">
body
{
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1080px;
  font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #fdfdfd;
}
</style>
</head>

<body>

<table align="center">
<td align="center">
<h2>TMM2018</h2>
<h1>DRFN: Deep Recurrent Fusion Network for Single Image <br> Super-Resolution with Large Factors</h1>
</td>
</table>

<br>
<br>
<table align="center" cellpadding="0" cellspacing="0">
<tr>
	<td><img border=0 height=400 width=500 src="xiaoguo.jpg"></td>
	<td><div style="margin-left:-400px;"><img border=0 height=300 width=500 src="parameter.jpg"></div></td>
</tr>
<tr>
	<td align="center"> <br><br> </td>
</tr>
<tr>
	<td align="center"><img border=0 height=350 width=960 src="pipeline.jpg"></td>
</tr>
</table>


<br>
<h2><p><font size="6"><b>Abstract</b></font></p></h2>
<hr/>
<p><font size="5" face="Palatino Linotype">Recently, single-image super-resolution has made great progress due to the development of deep convolutional neural networks (CNNs). The vast majority of CNN-based models use a predefined upsampling operator, such as bicubic interpolation, to upscale input low-resolution images to the desired size and learn nonlinear mapping between the interpolated image and ground truth high-resolution (HR) image. However, interpolation processing can lead to visual artifacts as details are over smoothed, particularly when the super-resolution factor is high. In this paper, we propose a deep recurrent fusion network (DRFN), which utilizes transposed convolution instead of bicubic interpolation for upsampling and integrates different-level features extracted from recurrent residual blocks to reconstruct the final HR images. We adopt a deep recurrence learning strategy and, thus, have a larger receptive field, which is conducive to reconstructing an image more accurately. Furthermore, we show that the multilevel fusion structure is suitable for dealing with image super-resolution problems. Extensive benchmark evaluations demonstrate that the proposed DRFN performs better than most current deep learning methods in terms of accuracy and visual effects, especially for large-scale images, while using fewer parameters.
</font></p>


<br>
<h2><p><font size="6"><b>Downloads</b></font></p></h2>
<hr/>
<div align="left">
		<table>						
		<tr align="left">
		<td>
			<font size="5"><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425771" target="_blank">[DRFN.pdf]</a></font>
		</td>
		<td>
			<font size="5">: The paper.</font>
		</td>	
		</tr>	
							
		<tr align="left">
		<td>
		<font size="5">[Results.zip]</font>
		</td>
		<td>
			<font size="5">: Experimental results.</font>
		</td>	
		</tr>
					
		<tr align="left">
		<td>
		<font size="5"><a href="https://github.com/Mhaiyang/DRFN" target="_blank">[Code]</a></font>
		</td>
		<td>
			<font size="5">: Source code.</font>
		</td>	
		</tr>	
			
			
		</table>
</div>
<br>
<br>


<h2><p><font size="6" color="black"><b>BibTex</b>&nbsp(DOI)</font></p></h2>
<hr/>								
<font size="4">
@article{yang2018drfn,<br>
&nbsp;&nbsp;&nbsp;&nbsp;title={DRFN: Deep Recurrent Fusion Network for Single-Image Super-Resolution With Large Factors},<br>
&nbsp;&nbsp;&nbsp;&nbsp;author={Yang, Xin and Mei, Haiyang and Zhang, Jiqing and Xu, Ke and Yin, Baocai and Zhang, Qiang and Wei, Xiaopeng},<br>
&nbsp;&nbsp;&nbsp;&nbsp;journal={IEEE Transactions on Multimedia},<br>
&nbsp;&nbsp;&nbsp;&nbsp;volume={21},<br>
&nbsp;&nbsp;&nbsp;&nbsp;number={2},<br>
&nbsp;&nbsp;&nbsp;&nbsp;pages={328--337},<br>
&nbsp;&nbsp;&nbsp;&nbsp;year={2018},<br>
&nbsp;&nbsp;&nbsp;&nbsp;publisher={IEEE}<br>
}
</font>


</body>

</html>
