<!DOCTYPE html>
<html>
<head>
<title>TPAMI2022_GDNet-B</title>

<style media="screen" type="text/css">
body
{
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1080px;
  font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #fdfdfd;
}
</style>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>
	<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">
	<script src="http://ajax.aspnetcdn.com/ajax/jQuery/jquery-1.8.0.js"></script>
</head>

<body>
<h3 align="center"><i><font size="3" face="Palatino Linotype">IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI) 2022</font></i></h3>

<table align="center">
<td align="center">
<h1>Large-Field Contextual Feature Learning for Glass Detection</h1>
<h3>
	<a href="http://mhaiyang.github.io" target="_blank"><font size="3"><b>Haiyang Mei</b></font></a><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="https://xinyangdut.github.io/" target="_blank"><font size="3"><b>Xin Yang</b></font></a><sup><font size="2">1,*</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Letian Yu</b></font><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Qiang Zhang</b></font><sup><font size="2">1</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<font size="3"><b>Xiaopeng Wei</b></font><sup><font size="2">1,*</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;
	<a href="https://www.cs.cityu.edu.hk/~rynson/" target="_blank"><font size="3"><b>Rynson W.H. Lau</b></font></a><sup><font size="2">2,*</font></sup>&nbsp;&nbsp;&nbsp;&nbsp;

	<br>
</h3>

<sup><font size="2">1</font></sup>
<b><a><font size="3">Dalian University of Technology</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;
<sup><font size="2">2</font></sup>
<b><a><font size="3">City University of Hong Kong</font></a></b>&nbsp;&nbsp;&nbsp;&nbsp;


<!--<br>-->
<!--<br>&nbsp;-->
<!--&lt;!&ndash;<sup><font size="2">&dagger;</font></sup>&ndash;&gt;-->
<!--<sup><font size="3">*</font></sup>-->
<!--<a><font size="3"> Corresponding author</font></a>-->
<br>
<br>&nbsp;

	<b><a><font size="3"> Contact us:&nbsp;&nbsp;&nbsp;&nbsp;<i>xinyang@dlut.edu.cn&nbsp;&nbsp;&nbsp;&nbsp;mhy666@mail.dlut.edu.cn</i></font></a></b>

</td>
</table>


<br><br>
<table align="center">
<tr>
	<td align="center"><img border=0 height=340 width=1000 src="overview.jpg"></td>
</tr>
</table>

<!--<br>-->
<!--<table align="center">-->
<!--<tr>-->
	<!--<td align="center"><img border=0 height=350 width=800 src="Glass.gif"></td>-->
<!--</tr>-->
<!--</table>-->

<!--<br>-->
<!--<h2><p><font size="6"><b>Glass Segmentation</b></font></p></h2>-->
<!--<hr/>-->

<h4><p><font size="5" color="black"><b>1. Abstract</b></font></p></h4>
<font size="4" face="Palatino Linotype">Glass is very common in our daily life. Existing computer vision systems neglect it and thus may have severe consequences, e.g., a robot may crash into a glass wall. However, sensing the presence of glass is not straightforward. The key challenge is that arbitrary objects/scenes can appear behind the glass. In this paper, we propose an important problem of detecting glass surfaces from a single RGB image. To address this problem, we construct the first large-scale glass detection dataset (GDD) and propose a novel glass detection network, called GDNet-B, which explores abundant contextual cues in a large field-of-view via a novel large-field contextual feature integration (LCFI) module and integrates both high-level and low-level boundary features with a boundary feature enhancement (BFE) module. Extensive experiments demonstrate that our GDNet-B achieves satisfying glass detection results on the images within and beyond the GDD testing set. We further validate the effectiveness and generalization capability of our proposed GDNet-B by applying it to other vision tasks, including mirror segmentation and salient object detection. Finally, we show the potential applications of glass detection and discuss possible future research directions.
</font>

<!--<br>-->
<br>
<h4><p><font size="5" color="black"><b>2. Boundary Feature Enhancement (BFE)</b></font></p></h4>

<table align="center">
<tr>
	<td align="center"><img border=0 height=250 width=600 src="bfe.jpg"></td>
</tr>
</table>

<font size="4" face="Palatino Linotype">Since the boundary is a strong cue for humans to distinguish a glass region, we further introduce the boundary cue to help boost the glass detection accuracy. Integrating boundary information can help glass detection in both segmentation and localization. In BFE, the input features are passed through four parallel branches, and the outputs of all branches are fused to generate glass boundary features, which are then used to predict the glass boundary map and complement the input features.</font>


<!--<br>-->
<!--<h2><p><font size="6"><b>PDNet</b></font></p></h2>-->
<!--<hr/>-->
<!--<table align="center">-->
<!--<tr>-->
	<!--&lt;!&ndash;<td align="center"><img border=0 height=270 width=960 src="pipeline.png"></td>&ndash;&gt;-->
<!--</tr>-->
<!--</table>-->

<!--<br>-->
<!--<h2><p><font size="6"><b>Visual Results</b></font></p></h2>-->
<!--<hr/>-->
<!--<table align="center">-->
<!--<tr>-->
	<!--&lt;!&ndash;<td align="center"><img border=0 height=300 width=900 src="CVPR2020_Glass_1.gif"></td>&ndash;&gt;-->
<!--</tr>-->
<!--</table>-->


<br>
<h4><p><font size="5"><b>3. Downloads</b></font></p></h4>
<!--<hr/>-->
<div align="left">
		<table>
<!--		<tr align="left">-->
<!--		<td>-->
<!--			<font size="4">Paper</font>-->
<!--		</td>-->
<!--		<td>-->
<!--&lt;!&ndash;			<font size="4">: [ <a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mei_Depth-Aware_Mirror_Segmentation_CVPR_2021_paper.pdf" target="_blank">PDNet.pdf</a> ]</font>&ndash;&gt;-->
<!--			<font size="4">: [ PGSNet.pdf ]</font>-->
<!--		</td>-->
<!--		</tr>-->

		<!--<tr align="left">-->
		<!--<td>-->
			<!--<font size="4">Glass Detection Dataset</font>-->
		<!--</td>-->
		<!--<td>-->
		<!--<font size="4">: [ Google Drive ]</font>-->
		<!--&lt;!&ndash;<font size="4">: <a href="" target="_blank">[ Google Drive ]</a></font>&ndash;&gt;-->
		<!--</td>-->
		<!--</tr>-->

<!--		<tr align="left">-->
<!--		<td>-->
<!--			<font size="4">Experimental results</font>-->
<!--		</td>-->
<!--		<td>-->
<!--&lt;!&ndash;			<font size="4">: [ <a href="https://drive.google.com/file/d/1GP1_rm6FSRKVJ1AxV-DSquKjXtpNVF32/view?usp=sharing" target="_blank">Google Drive</a> ]</font>&ndash;&gt;-->
<!--&lt;!&ndash;			<font size="4">[ <a href="https://pan.baidu.com/s/1rFVaXeH3Ob1B5VfoeYLgZw" target="_blank">Baidu Disk</a>, fetch code: rrr3 ]</font>&ndash;&gt;-->
<!--			<font size="4">: [ <a href="" target="_blank">Google Drive</a> ]</font>-->
<!--			<font size="4">[ <a href="" target="_blank">Microsoft OneDrive</a> ]</font>-->
<!--			<font size="4">[ <a href="" target="_blank">Baidu Disk</a>, fetch code: rgbp ]</font>-->
<!--		</td>-->

<!--		</tr>-->

<!--		<tr align="left">-->
<!--		<td>-->
<!--			<font size="4">Pre-trained model</font>-->
<!--		</td>-->
<!--		<td>-->
<!--			<font size="4">: [ <a href="" target="_blank">Google Drive</a> ]</font>-->
<!--			<font size="4">[ <a href="" target="_blank">Microsoft OneDrive</a> ]</font>-->
<!--			<font size="4">[ <a href="" target="_blank">Baidu Disk</a>, fetch code: rgbp ]</font>-->
<!--		</td>-->
<!--		</tr>-->

		<tr align="left">
		<td>
			<font size="4">Model</font>
		</td>
		<td>
<!--			<font size="4">: [ <a href="" target="_blank">Google Drive</a> ]</font>-->
			<font size="4">: [ Google Drive ]</font>
<!--			<font size="4">[ <a href="" target="_blank">Microsoft OneDrive</a> ]</font>-->
<!--			<font size="4">[ <a href="" target="_blank">Baidu Disk</a>, fetch code: pami ]</font>-->
			<font size="4">[ Baidu Disk, fetch code: pami ]</font>
<!--			<font size="4">: [ Google Drive ]</font>-->
<!--			<font size="4">[ Microsoft OneDrive ]</font>-->
<!--			<font size="4">[ Baidu Disk, fetch code: xxxx ]</font>-->
		</td>
		</tr>
		<tr align="left">
		<td>
			<font size="4">Results</font>
		</td>
		<td>
<!--			<font size="4">: [ <a href="" target="_blank">Google Drive</a> ]</font>-->
			<font size="4">: [ Google Drive ]</font>
<!--			<font size="4">[ <a href="" target="_blank">Microsoft OneDrive</a> ]</font>-->
<!--			<font size="4">[ <a href="" target="_blank">Baidu Disk</a>, fetch code: pami ]</font>-->
			<font size="4">[ Baidu Disk, fetch code: pami ]</font>
<!--			<font size="4">: [ Google Drive ]</font>-->
<!--			<font size="4">[ Microsoft OneDrive ]</font>-->
<!--			<font size="4">[ Baidu Disk, fetch code: xxxx ]</font>-->
		</td>
		</tr>

		<tr align="left">
		<td>
			<font size="4">Code</font>
		</td>
		<td>
			<!--<font size="4">: [ Code ]</font>-->
			<font size="4">: [ <a href="https://github.com/Mhaiyang/TPAMI2022_GDNet-B" target="_blank">Github</a> ] </font>
		</td>
		</tr>

		</table>
</div>


<!--<h2><p><font size="6" color="black"><b>Dataset</b></font></p></h2>-->
<!--<hr/>-->

<!--<font size="4"> Both <font size="4" color="red">training set</font> and <font size="4" color="red">testing set</font> can be obtained via form request! </font>-->
<!--<br><br>-->

<!--<font size="3">-->
<!--	To request access to the dataset for non-commercial use, please review the terms and conditions. If you agree with them, please fill the form below and then click the "<font color="black">Send Request</font>" button to achieve a request. Please fill in your official university/company email address. Thank you!-->

<!--	<br>-->
<!--	<br>-->

<!--	<b>Terms and Conditions</b>-->
<!--	<br>-->

<!--The dataset can be used freely if you agree with all the following terms.<br>-->

<!-- - The dataset is used only for non-commercial purposes, such as teaching and research. You do not use the dataset or any of its modified versions for any purposes of commercial advantage or private financial gain.<br>-->
<!-- - You do not distribute the dataset or any of its modified versions to other individuals, institutes, companies, associations or public.<br>-->
<!-- - In case you use the dataset within your research papers, you refer to our publications on our website. If the dataset is used in media, a link to our website is included.<br>-->
<!-- - We reserve all rights that are not explicitly granted to you. The dataset is provided as is, and you take full responsibility for any risk of using it. There may be inaccuracies although we tried, and will try our best to rectify any inaccuracy once found.-->

<!--</font>-->
<!--<br>-->

<!--<h3>Sending Request to Prof. Xin Yang (xinyang@dlut.edu.cn):</h3>-->

<!--<form class="form" id="emailForm">-->
<!--	Name:<br>-->
<!--    <input id="first" name='name' type="text" placeholder="Your name..." class="form__input" />-->
<!--	<br><br>-->
<!--	Institute:<br>-->
<!--    <input id="second" name='institute' type="text" placeholder="Your institute..." class="form__input" />-->
<!--	<br><br>-->
<!--	E-mail:<br>-->
<!--	<input id="third" name='email' type="text" placeholder="Your E-mail address..." class="form__input" />-->
<!--    &lt;!&ndash;<textarea id="third" name='e-mail' type="text" placeholder="Your E-mail..." class="form__input"></textarea>&ndash;&gt;-->
<!--</form>-->
<!--<br>-->
<!--<button id="btnSubmit">Send Request</button>-->
<!--<br><br><br><br>-->

<!--<br><br><br><br>-->
<!--<h2><p><font size="6" color="black"><b>Report</b></font></p></h2>-->
<!--<hr/>-->
<!--<table align="center">-->
<!--<tr>-->
	<!--<td align="center"><embed src="report.mp4" width="800" height="450"></td>-->
<!--</tr>-->
<!--</table>-->


<br>
<h4><p><font size="5" color="black"><b>4. Applications</b></font></p></h4>

<table align="center">
<tr>
	<td align="center"><img border=0 height=400 width=550 src="application.jpg"></td>
</tr>
</table>

<font size="4" face="Palatino Linotype">Automatic glass detection has various possible applications. Here, we envision two potential ones: obstacle avoidance for drones and intelligence photography/editing. If a drone is equipped with the ability to detect glass, it can easily find out where the glass is and avoid crashing into the glass (e.g., Figure (b)). In addition, if a phone camera is equipped with the ability to detect glass, it can identify the glass and then remove the reflections from the glass region to obtain the desired result (e.g., Figure (d)).</font>


<br>
<h4><p><font size="5" color="black"><b>5. BibTex</b></font></p></h4>
<!--<hr/>-->
<font size="3">
@article{Haiyang:GDNet-B:2022,<br>
&nbsp;&nbsp;&nbsp;&nbsp;author = {Mei, Haiyang and Yang, Xin and Yu, Letian and Zhang, Qiang and Wei, Xiaopeng and Lau, Rynson W. H.},<br>
&nbsp;&nbsp;&nbsp;&nbsp;title = {Large-Field Contextual Feature Learning for Glass Detection},<br>
&nbsp;&nbsp;&nbsp;&nbsp;booktitle = {IEEE Transactions on Pattern Analysis and Machine Intelligence (TPAMI)},<br>
&nbsp;&nbsp;&nbsp;&nbsp;pages={1-17},,<br>
&nbsp;&nbsp;&nbsp;&nbsp;year = {2022}<br>
}
</font>


<br>
<h4><p><font size="5" color="black"><b>6. Website Visit Statistics</b></font></p></h4>
<!--<br><br>-->
<!--<h2>Website visit statistics</h2>-->
<!--<hr/>-->
<script type="text/javascript" src="//rf.revolvermaps.com/0/0/6.js?i=5pxzrkcgi6y&amp;m=7&amp;c=e63100&amp;cr1=ffffff&amp;f=arial&amp;l=0&amp;bv=90&amp;lx=-420&amp;ly=420&amp;hi=20&amp;he=7&amp;hc=a8ddff&amp;rs=80" async="async"></script>


</body>

</html>
