<!DOCTYPE html>
<html>
<head>
<title>Haiyang Mei</title>

    <meta http-equiv="Content-Type" content="text/html; charset=utf-8" />

<style media="screen" type="text/css">
body
{
  border: 0pt none;
  font-family: inherit;
  font-size: 100%;
  font-style: inherit;
  font-weight: inherit;
  margin: 0pt;
  outline-color: invert;
  outline-style: none;
  outline-width: 0pt;
  padding: 0pt;
  vertical-align: baseline;
}
body {
  position: relative;
  margin: 3em auto 2em auto;
  width: 1080px;
  font-family: Times New Roman, Lato, Verdana, Helvetica, sans-serif;
  font-size: 14px;
  background: #fdfdfd;
}
</style>

<script>
var _hmt = _hmt || [];
(function() {
  var hm = document.createElement("script");
  hm.src = "https://hm.baidu.com/hm.js?1ec4ad5c61857459aa78d5ee7ddee28d";
  var s = document.getElementsByTagName("script")[0];
  s.parentNode.insertBefore(hm, s);
})();
</script>

</head>

<body>
		
	<table align="center">
	<tr>
	<td align="center"><img border=0 height=190 width=200 src="mhy.jpg"></td>
	<td align="center">&nbsp</td>
	<td align="center">&nbsp</td>
	<td align="center">
			<td align="center"><h2>Haiyang Mei</h2>
		<p><font size=+1><b>梅海洋</b><br><br>Ph.D Student<br>Dalian University of Technology</font></p>
		<p><font size=+1>Email: <i>mhy666@mail.dlut.edu.cn</i></font><br></p>
			</td>			
	</td>		
	</tr>
	</table>
	
	<h2>Biography</h2>
	<hr/>
	<p><font size="4">I am currently a third-year Ph.D. student in the <a href="http://cs.dlut.edu.cn/">School of Computer Science and Technology</a>, <a href="https://www.dlut.edu.cn/">Dalian University of Technology</a>, supervised by Prof Xiaopeng Wei and <a href="https://xinyangdut.github.io/" target="_blank">Prof Xin Yang</a>, and also received academic guidance from <a href="http://www.cs.cityu.edu.hk/~rynson/" target="_blank">Rynson W.H. Lau</a> and <a href="https://dongshuhao.github.io/" target="_blank">Bo Dong</a>. Before that, I received the B.Eng. degree from the School of Control Science and Engineering, <a href="https://www.dlut.edu.cn/">Dalian University of Technology.</a> in 2017.</font></p>
	<br>
	
	
	<h2>Research Interests</h2>
	<hr/>
	<p><font size="4">My primary research interest is in designing effective visual understanding models for the vision systems. This work can help AI agents in scene-level understanding, reasoning, and decision making.
		<br>
		<br>
		My recent endeavor is on <font color="red">scene confusing-discovery</font>, which aims to mine the confusing/special yet meaningful object/region in the scene. In particular, the objects I focus on include <font color="blue">glass</font>, <font color="blue">mirror</font>, <font color="blue">camouflaged object</font>, and <font color="blue">salient object</font>, which are very common in daily life scenes but can confuse the vision systems due to their inherently special properties. Therefore, detecting and segmenting such objects from the scene plays an essential role in accurate scene understanding and can benefit a wide range of computer vision, graphics, and multimedia applications, including image classification, visual tracking, content-aware image editing, medical image diagnosis, and robotic navigation. However, this task has not been fully explored and remains an unsolved and challenging problem. Both glass and mirror do not have their own visual appearances but only transmit/reflect the appearances of their surroundings, making them fundamentally different from other common objects that have been addressed well by the state-of-the-art segmentation methods. The camouflaged/salient object is the object that is ``seamlessly'' embedded in their surroundings or most attention-grabbing and could be easily cluttered by the background in the complex scenes. I am working toward exploring useful cues and effective methods for accurate segmentation.
		<br>
		<br>
		Besides, my early work was on <font color="red">image super-resolution</font>, which is to reconstruct the high-quality, visually satisfactory high-resolution image from the input low-resolution one and is the cornerstone of providing more detailed information for scene analysis and understanding.
	</font></p>
	<br>

	<h2>News!</h2>
	<hr/>
	<ul>
		<li><font size="4"><b>2022.03.08:</b> One paper was accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=83" target="_blank">TIP</a> !</font></li>
		<li><font size="4"><b>2022.03.02:</b> One paper was accepted by <a href="http://cvpr2022.thecvf.com/" target="_blank">CVPR 2022</a> ! </font></li>
		<li><font size="4"><b>2021.03.25:</b> One paper was accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" target="_blank">TCSVT</a> !</font></li>
		<li><font size="4"><b>2021.03.17:</b> One paper was accepted by <a href="https://ieeexplore.ieee.org/xpl/RecentIssue.jsp?punumber=76" target="_blank">TCSVT</a> !</font></li>
		<li><font size="4"><b>2021.03.04:</b> Two papers were accepted by <a href="http://cvpr2021.thecvf.com/" target="_blank">CVPR 2021</a> ! (One Oral)</font></li>
		<li><font size="4"><b>2020.03.06:</b> One paper was accepted by <a href="https://www.2020.ieeeicme.org/" target="_blank">ICME 2020</a> !</font></li>
		<li><font size="4"><b>2020.02.24:</b> One paper was accepted by <a href="http://cvpr2020.thecvf.com/" target="_blank">CVPR 2020</a> !</font></li>
	</ul>
	<br>
	
	<h2>Publications &nbsp<a href="https://scholar.google.com/citations?user=i105U7QAAAAJ" target="_blank">[Google Scholar]</a></h2>
	<hr/>
	<table>
	<tbody>
		<tr>
			<td><font size="4"><b>2022</b></font></td>
		</tr>

		<tr></tr>
		<tr></tr>
		<tr></tr>

		<tr>
			<td><font size="4">1.</font></td>
			<td><center><img width="300" height="100" src="coming_soon.png"></center></td>
			<td><font size="4">Progressive Glass Segmentation
				<br>
<!--				Letian Yu<font size="3" color="DeepSkyBlue ">*</font>, <b>Haiyang Mei</b><font size="3" color="DeepSkyBlue ">*</font>, Wen Dong, Ziqi Wei, Li Zhu, Yuxin Wang, Xin Yang. (<font size="3" color="DeepSkyBlue ">*</font> <font size="3">joint first authors</font>)-->
				<br>
				<i>IEEE Transactions on Image Processing (<b>TIP</b>) 2022 </i>
				<br>
<!--				[<b><a href="">PDF</a> </b>|<a href="TIP2022-PGSNet/index.html" target="_blank"><b>Project Page</b></a>]-->
				[<b>PDF</b>|<a href="TIP2022-PGSNet/index.html" target="_blank"><b>Project Page</b></a>]
<!--				[<b>PDF</b>|<b>Project Page</b>]-->
			</font></td>
		</tr>

		<tr></tr>
		<tr></tr>
		<tr></tr>

		<tr>
			<td><font size="4">2.</font></td>
			<td><center><img width="300" height="100" src="coming_soon.png"></center></td>
			<td><font size="4">Glass Segmentation using Intensity and Spectral Polarization Cues
				<br>
<!--				<b>Haiyang Mei</b>, Bo Dong, Wen Dong, Jiaxi Yang, Seung-Hwan Baek, Felix Heide, Pieter Peers, Xiaopeng Wei, Xin Yang.-->
				<br>
				<i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2022</i>
				<br>
<!--				[<b><a href="">PDF</a></b>|<a href="CVPR2022_PGSNet/index.html" target="_blank"><b>Project Page</b></a>]-->
				[<b>PDF</b>|<a href="CVPR2022_PGSNet/index.html" target="_blank"><b>Project Page</b></a>]
<!--				[<b>PDF</b>|<b>Project Page</b>]-->
			</font></td>
		</tr>

		<tr>
			<td><br><br><br><font size="4"><b>2021</b></font></td>
		</tr>

		<tr></tr>
		<tr></tr>
		<tr></tr>

		<tr>
			<td><font size="4">1.</font></td>
			<td><center><img width="300" height="145" src="pdnet_teaser.png"></center></td>
			<td><font size="4">Depth-Aware Mirror Segmentation
				<br>
				<b>Haiyang Mei</b>, Bo Dong, Wen Dong, Pieter Peers, Xin Yang, Qiang Zhang, Xiaopeng Wei
				<br>
				<i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2021 (<font color="purple"><b>Oral</b></font>)</i>
				<br>
				[<b><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mei_Depth-Aware_Mirror_Segmentation_CVPR_2021_paper.pdf">PDF</a> </b>|<a href="CVPR2021_PDNet/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>

		<tr></tr>
		<tr></tr>
		<tr></tr>

		<tr>
			<td><font size="4">2.</font></td>
			<td><center><img width="300" height="125" src="pfnet_teaser.png"></center></td>
			<td><font size="4">Camouflaged Object Segmentation with Distraction Mining
				<br>
				<b>Haiyang Mei</b>, Ge-Peng Ji, Ziqi Wei, Xin Yang, Xiaopeng Wei, Deng-Ping Fan
				<br>
				<i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2021</i>
				<br>
				[<b><a href="https://openaccess.thecvf.com/content/CVPR2021/papers/Mei_Camouflaged_Object_Segmentation_With_Distraction_Mining_CVPR_2021_paper.pdf">PDF</a></b>|<a href="CVPR2021_PFNet/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>

		<tr></tr>
		<tr></tr>
		<tr></tr>

		<tr>
			<td><font size="4">3.</font></td>
			<td><center><img width="300" height="130" src="dcenet_teaser.png"></center></td>
			<td><font size="4">Exploring Dense Context for Salient Object Detection
				<br>
				<b>Haiyang Mei</b>, Yuanyuan Liu, Ziqi Wei, Dongsheng Zhou, Xiaopeng Wei, Qiang Zhang, Xin Yang
				<br>
				<i>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>) 2021</i>
				<br>
				[<b><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9389751">PDF</a></b>|<a href="TCSVT2021-DCENet/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>

		<tr></tr>
		<tr></tr>
		<tr></tr>

		<tr>
			<td><font size="4">4.</font></td>
			<td><center><img width="300" height="220" src="tsan_teaser.png"></center></td>
			<td><font size="4">A Two-Stage Attentive Network for Single Image Super-Resolution
				<br>
				Jiqing Zhang, Chengjiang Long, Yuxin Wang, Haiyin Piao, <b>Haiyang Mei</b>, Xin Yang, Baocai Yin
				<br>
				<i>IEEE Transactions on Circuits and Systems for Video Technology (<b>TCSVT</b>) 2021</i>
				<br>
				[<b><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9395490">PDF</a></b>|<a href="TCSVT2021-TSAN/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>

		<tr>
			<td><br><br><br><font size="4"><b>2020</b></font></td>
		</tr>

		<tr>
			<td><font size="4">1.</font></td>
			<td><center><img width="300" height="240" src="glass_teaser.png"></center></td>
			<td><font size="4">Don't Hit Me! Glass Detection in Real-World Scenes
				<br>
				<b>Haiyang Mei</b>, Xin Yang, Yang Wang, Yuanyuan Liu, Shengfeng He,
				<br>
				Qiang Zhang, Xiaopeng Wei, Rynson W.H. Lau
				<br>
				<i>The IEEE/CVF Conference on Computer Vision and Pattern Recognition (<b>CVPR</b>) 2020</i>
				<br>
				[<b><a href="http://openaccess.thecvf.com/content_CVPR_2020/papers/Mei_Dont_Hit_Me_Glass_Detection_in_Real-World_Scenes_CVPR_2020_paper.pdf" target="_blank">PDF</a></b>|<a href="CVPR2020_GDNet/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>

		<tr></tr>
		<tr></tr>
		<tr></tr>

		<tr>
			<td><font size="4">2.</font></td>
			<td><center><img width="300" height="130" src="icme_teaser.png"></center></td>
			<td><font size="4">Multi-Context And Enhanced Reconstruction Network For Single Image Super Resolution
				<br>
				Jiqing Zhang, Chengjiang Long, Yuxin Wang, Xin Yang, <b>Haiyang Mei</b>, and Baocai Yin
				<br>
				<i>IEEE International Conference on Multimedia and Expo (<b>ICME</b>) 2020</i>
				<br>
				[<b><a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=9102868" target="_blank">PDF</a></b>|<a href="ICME2020_MCERN/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>


		<tr>
			<td><br><br><br><font size="4"><b>2019</b></font></td>
		</tr>

		<tr>
			<td><font size="4">1.</font></td>
			<td><center><img width="300" src="ICCV2019_MirrorNet/teaser.jpg"></center></td>
			<td><font size="4">Where Is My Mirror?
				<br>
				Xin Yang<font size="3" color="DeepSkyBlue ">*</font>, <b>Haiyang Mei</b><font size="3" color="DeepSkyBlue ">*</font>, Ke Xu, Xiaopeng Wei, Baocai Yin, and Rynson Lau. (<font size="3" color="DeepSkyBlue ">*</font> <font size="3">joint first authors</font>)
				<br>
				<i>IEEE International Conference on Computer Vision (<b>ICCV</b>) 2019</i>
				<br>
				[<b><a href="https://arxiv.org/pdf/1908.09101v2.pdf" target="_blank">PDF</a></b>|<a href="ICCV2019_MirrorNet/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>

		<tr>
			<td><br><br><br><font size="4"><b>2018</b></font></td>
		</tr>

		<tr>
			<td><font size="4">1.</font></td>
			<td><center><img width="300" src="tmm_teaser.jpg"></center></td>
			<td><font size="4">DRFN: Deep Recurrent Fusion Network for Single Image Super-Resolution with Large Factors
				<br>
				Xin Yang, <b>Haiyang Mei</b>, Jiqing Zhang, Ke Xu, Baocai Yin, Qiang Zhang, and Xiaopeng Wei.
				<br>
				<i>IEEE Transactions on Multimedia (<b>TMM</b>) 2018</i>
				<br>
			[<a href="https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=8425771" target="_blank"><b>PDF</b></a>|
				<a href="TMM2018-DRFN/index.html" target="_blank"><b>Project Page</b></a>]
			</font></td>
		</tr>
		
	</tbody>
	</table>
	<br>



	<h2>Patent</h2>
	<hr/>
	<table>
	<tr>
		<td><font size="3"><b>1.</b> &nbsp 一种利用回归树场的图像超分辨率放大方法. &nbsp 杨鑫, <b>梅海洋</b>, 许可, 魏小鹏, 尹宝才. &nbsp 201710859709.0</font></td>
	</tr>
	</table>

	<br><br>
	<h2>Website visit statistics</h2>
	<hr/>
	<script type='text/javascript' id='clustrmaps' src='//cdn.clustrmaps.com/map_v2.js?cl=ffffff&w=400&t=tt&d=YVHaD32jOtcB3Eiq9UMYVAERx0kd9bogZFwa-ljWvqw&co=2d78ad&cmo=3acc3a&cmn=ff5353&ct=ffffff'></script>



</body>

</html>
